---
title: "Assembly and cross-assembly"
teaching: 0
exercises: 120
questions:
objectives:
- "Assemble the metavirome from 3 samples"
keypoints:
- Flye can be used to assemble long and noisy nanopore reads from metagenomic samples.
- Samples can be assembled individually and combined in a cross-assembly
- vClust can be used to asses the diversity of sequences in your assembly
---

# Assembly and cross-assembly

*Sequence assembly* is the reconstruction of long contiguous genomic sequences 
(called *contigs* or *scaffolds*) from short sequencing reads. Before 2014, a common 
approach in metagenomics was to compare the short sequencing reads to the genomes of 
known organisms in the database (and some studies today still take this approach). However, 
recall that most of the sequences of a metavirome are unknown, meaning that they yield no 
matches when are compared to the databases. Because of this, we need of database-independent 
approaches to describe new viral sequences. As bioinformatic tools improved, sequence assembly 
enabled recovery of longer sequences of the metagenomic datasets. Having a longer sequence means 
having more information to classify it, so using metagenome assembly helps to characterize 
complex communities such as the gut microbiome.

In this lesson you will assemble the metavirome in two different ways using the tool 
[Flye](https://github.com/mikolmogorov/Flye) introduced in [this article](https://www.nature.com/articles/s41587-019-0072-8). 
Flye was designed to work well with noisy long reads and for metagenomic samples. Since you work 
on draco, everything even slightly computationally expensive will be run through slurm. 
Please organize all the following steps in one or more sbatch scripts as you learned yesterday. 
Since every tool needs different amounts of resources, it is recommended to have a single 
script per tool. All code snippets presented here assume that you put them in an adequate sbatch 
script and the respective necessary resources are mentioned in the comments or the descriptions.

### Cross-Assembly

In a cross-assembly, **multiple samples are combined and assembled together**, allowing for the 
discovery of shared sequence elements between the samples. If a virus (or other sequence element) 
is present in several samples, its sequencing reads from the different samples will be assembled 
together in one contig. After this we can know which contigs are present in which sample by 
mapping the sequencing reads from each sample to the cross-assembly.

You will perform a cross-assembly of the samples you started working with yesterday. To this end, 
you have to concatenate the sample files and run flye on the merged file. Gzipped files can be 
concatenated just like text files with the command line tool cat and flye is installed in a 
conda environment on draco:

~~~
# activate conda environment with flye installation on draco
source /vast/groups/VEO/tools/miniconda3_2024/etc/profile.d/conda.sh && conda activate flye_v2.9.2

# merge the sequences
cat /path/to/*.fastq.gz > /path/to/all_samples.fastq.gz

# create a folder for the output cross-assembly
mkdir -p 10_results_assembly_flye/cross_assembly

# complete the flye command. This is the computationally expensive part
# and profits from many cores (30 is a good number). The used memory should
# not exceed 20GB of RAM. 
flye --out-dir 10_results_assembly_flye/cross_assembly ...
~~~
{: .language-bash}

[Here](https://github.com/mikolmogorov/Flye/blob/flye/docs/USAGE.md) you can find an overview 
over the possible parameters. Flye can be used for single-organism assemblies as well as metagenomic 
assemblies and your sequences were generated with the nanopore MinION platform and filtered to 
only contain high quality reads. Flye needs an estimate of the size of your metagenome, i.e., 
the combined length of the assembled contigs. There is no good way to accurately predict this if 
you do not know what's in your samples as in our case. How would you very roughly estimate this number?

After you finished your sbatch script with the ressource assignments and the completed commands, 
you can either run it directly or continue to expand it with the commands for the second approach 
described below. If you run it now, remember you can check the output of your script in the slurm 
log files which you can set with the sbatch parameters at the beginning of your script:

~~~
#SBATCH --output=10_results_assembly_flye/assembly_flye.slurm.%j.out
#SBATCH --error=10_results_assembly_flye/assembly_flye.slurm.%j.err
~~~
{: .language-bash}

Most often, the error output contains more than just errors and the corresponding file is the more informative one.

> ## Go through the results of flye
> flye creates an assembly in multiple steps. Your can read through the log file of flye you defined
> in the `#SBATCH --error=` parameter. Afterwards, you can find a list of all assembled contigs
> with additional information in the file `assembly_info.txt` in the output folder of your flye run.
> Which are the longest and shortest lengths? Whats the range of coverage values? How many circular
> contigs were assembled? 
{: .challenge}

### Separate assemblies

The second approach consists on performing separate assemblies for each sample and merging the 
resulting contigs in the end. Note that if a species is present in several samples, this final 
set will contain multiple contigs representing the same sequence, each of them coming from one 
sample. Because of this, we will further de-replicate the final contigs to get representative 
sequences.

To run separate assemblies, you can adapt the flye command used for the crossassembly to take 
each sample file individually and output the assemblies in separate folders in 10_results_assembly_flye. 
For this you can run a for loop over the respective files. The following expects the sample 
files to be called barcodeN.fastq.gz with N in (62, 63, 64):

~~~
# The individual assemblies need less memory than the crossassembly,
# but you can still use the same resources as before.
for barcode in $(seq 62 64)
do
	flye ... /path/to/barcode$barcode.fastq.gz ...
done
~~~
{: .language-bash}

Here, the command seq generates a sequence of integer numbers between its two arguments. 
Once the assemblies have finished, you will combine the contigs generated for each sample 
into a single file. Since the generated contigs are only assigned numbers by flye 
(not necessarily sequential), the same names will be present in each assembly. We have to 
rename them according to the sample they originate from for all contigs to have unique names.
We can do this using python and the Biopython package. Biopython provides many tools for the 
analysis of sequencing data, including tools for parsing and writing .fasta files. You can 
find the documentation on these [here](https://biopython.org/wiki/SeqIO).

To use this python package on draco, you can create your own virtual environment and use it 
to install all the packages you need. We will use this environment throughout the course for 
scripting and visualizing data. Creating a virtual environment is done by using the venv 
package, which is shipped with each (at least slightly recent) python installation. Note, 
that the environment will have its own copy of python binaries, by default the ones which were 
used to create the environment. After activating the environment, these binaries are then used 
to locally install and run python packages and your code.

~~~
# Use python3.9 on draco to create a virtual environment
$ python3.9 -m venv path/to/your/py3env

# activate the environment
$ source path/to/your/py3env/bin/activate

# update pip
$ pip install --upgrade pip

# install the packages we need
$ pip install biopython
~~~
{: .language-bash}

You can now write a python script which reads your contigs, changes their name and writes a 
new file with the results using biopython. The basic structure of the script could look like this:
 
~~~
from Bio import SeqIO
import os, sys

# read the arguments passed to your script
assembly = os.path.abspath(sys.argv[1])
 
with open(assembly) as file_handle:
  for record in SeqIO.parse(file_handle, "fasta"):
    # do something with the sequence name

# write the records with the new names
~~~
{: .language-python}

> ## python script for renaming contigs
> ```python
>import os, sys
>from Bio import SeqIO
>
>def main():
>
>    assembly = os.path.abspath(sys.argv[1])
>    assert assembly.endswith(".fasta")
>    
>    out_fasta = os.path.abspath(sys.argv[2])
>    assert out_fasta.endswith(".fasta")
>    
>    sample_id = sys.argv[3]
>    
>    # modify names of the scaffols and store in to_write list
>    to_write = list()
>    with open(assembly) as handle:
>        for record in SeqIO.parse(handle, "fasta"):
>            if record.id.startswith(sample_id): continue
>            record.id = f"{sample_id}_{record.id}"
>            to_write.append(record)
>
>    # write records in to_write to .fasta file
>    with open(out_fasta, "w") as fout:
>        SeqIO.write(to_write, fout, "fasta")
>
>
>if __name__ == "__main__":
>    main()
>```
> {: .source}
{: .solution}

This script should not be computationally expensive, but we will anyways execute it from 
within an sbatch script. We can also combine it with the script or scripts you already have 
written for the assemblies themselves. In this case it is important to deactivate the conda 
environment holding the flye installation before activating the environment you just created. 

> ## sbatch script for assemblies 
> ```bash
> #!/bin/bash
> #SBATCH --tasks=1
> #SBATCH --cpus-per-task=32
> #SBATCH --partition=standard
> #SBATCH --mem=20G
> #SBATCH --time=01:00:00
> #SBATCH --job-name=assembly_flye
> #SBATCH --output=10_results_assembly_flye/assembly_flye.slurm.%j.out
> #SBATCH --error=10_results_assembly_flye/assembly_flye.slurm.%j.err
>
> # run flye in metagenomic mode for de-novo assembly of viral contigs
> # First, activate the conda environment which holds the flye installation on draco:
> source /vast/groups/VEO/tools/miniconda3_2024/etc/profile.d/conda.sh && conda activate flye_v2.9.2
>
> # set a data directory holding your samples in .fastq.gz format
> datadir="../data/sequences"
> 
> # create a merged fastq.gz file by concatenating three samples:
> cat $datadir/barcode*.fastq.gz > $datadir/merged.fastq.gz
>
> # set a directory for ouputting results
> outdir="10_results_assembly_flye/cross_assembly"
> 
> # create a folder for the cross-assembly
> mkdir -p $outdir
> 
> # flye parameters (https://gensoft.pasteur.fr/docs/Flye/2.9/USAGE.html)
> # --nano-raw: tells flye about the input data. --nano-hq is also possible but results in a smaller assembly (Why?).
> # --meta: for metagenomes with uneven coverage
> # --genome-size: estimated size for metagenome assembly (mg size)
> # -t: threads
> flye --nano-raw $datadir/merged.fastq.gz --meta --genome-size 30m --out-dir $outdir -t 30
>
> # Run flye on all samples sequentially, save the results in separate folders named like the samples:
>
> outdir="10_results_assembly_flye/single_assemblies"
> mkdir -p $outdir
> for barcode in $(seq 62 64)
> do
>	  flye --nano-raw $datadir/barcode$barcode.fastq.gz --meta --genome-size 10m --out-dir $outdir/barcode$barcode -t 30
> done
>
> # close the conda environment
> conda deactivate
>
> # activate your virtual environment
> source path/to/your/py3env/bin/activate
>
> # rename the contings in the generated single assemblies with a python script.
> # It assumes three parameters here, first the input file name, second the output file name and third,
> # the sample name to add to each contig name in the respective fasta file.
> for barcode in $(seq 62 64)
> do
>	  python3 10_run_rename_scaffolds.py $outdir/barcode$barcode/assembly.fasta $outdir/barcode$barcode.fasta barcode$barcode
> done
> deactivate
>
> cat $outdir/barcode*.fasta > $outdir/assembly.fasta
>```
> {: .source}
{: .solution}

To de-replicate the scaffolds, you will cluster them at 95% Average Nucleotide Identify (ANI) 
over 85% of the length of the shorter sequence, cutoffs often used to cluster viral genomes at 
the species level. This can be done with the tool [vClust](https://github.com/refresh-bio/vclust) 
and results in both, clustering complete viral genomes at the species level and clustering genome 
fragments along with very similar and longer sequences. vClust can also output cluster representatives, 
which will be the longest seuquences within a cluster. Use this mode to get the information we 
need to dereplicate our merged single assemblies. Also apply vClust to the cross-assembly, this 
will give us more information on the assembled sequences. You can play with the similarity cutoffs 
(and metrics) used for clustering to see how they affect the results. vClust needs to align all 
sequences to eachother and can run heavily in parallel. Remember to put this step into a sbatch 
script again and assign around 30 cores and 20GB of RAM.

~~~
# vClust is a python script and can be run by simply calling it on draco
# you have to run it with python 3.9
vclust='python3.9 /home/groups/VEO/tools/vclust/v1.0.3/vclust.py'

$vclust prefilter -i 10_results_assembly_flye/single_assemblies/assembly.fasta ...
$vclust align ...
$vclust cluster ...
~~~
{: .language-bash}

After vClust ran successfully, you need to write a python script to filter the assembly according 
to the information provided by vClust. To parse a tabular file in the format of CSV or TSV (comma- 
or tab-separated valus), the python package pandas can be used. To use it, first install it into 
the virtual environment:

~~~
# activate the environment
$ source path/to/your/py3env/bin/activate

# install the packages we need
$ pip install pandas
~~~
{: .language-bash}

Now you can write a python script which filters the assemblies corresponding to the output of vClust:

~~~
from Bio import SeqIO
import pandas as pd
import os, sys

# read the tsv file generated by vClust
cluster_df = pd.read_csv('path/to/the/file.tsv', sep='\t')
 
with open(assembly) as file_handle:
  for record in SeqIO.parse(file_handle, "fasta"):
    # check if the contig is in the set of representatives

# write the records which passed the test
...
~~~
{: .language-python}

> ## python script for filtering similar contigs
> ```python
> import os, sys
> import pandas as pd
> from Bio import SeqIO
>
> def main():
>
>     assembly_filename = os.path.abspath(sys.argv[1])
>     assert assembly_filename.endswith(".fasta")
>    
>     out_filename = os.path.abspath(sys.argv[2])
>     assert out_filename.endswith(".fasta")
>    
>     cluster_reps_filename = os.path.abspath(sys.argv[3])
>     assert cluster_reps_filename.endswith(".tsv")
>
>     cluster_reps_df = pd.read_csv(cluster_reps_filename, sep='\t')
>     cluster_reps_set = set(cluster_reps_df["cluster"])
>	
>     to_write = list()
>     with open(assembly_filename) as handle:
>         for record in SeqIO.parse(handle, "fasta"):
>             if record.id in cluster_reps_set: to_write.append(record)
>
>     # write records in to_write to .fasta file
>     with open(out_filename, "w") as fout:
>         SeqIO.write(to_write, fout, "fasta")
>
>
> if __name__ == "__main__":
>     main()
>```
> {: .source}
{: .solution}

> ## sbatch script for dereplication
> ```bash
> #!/bin/bash
> #SBATCH --tasks=1
> #SBATCH --cpus-per-task=32
> #SBATCH --partition=standard
> #SBATCH --mem=20G
> #SBATCH --time=01:00:00
> #SBATCH --job-name=assessment_vclust
> #SBATCH --output=20_results_assessment_vclust/assessment_vclust.slurm.%j.out
> #SBATCH --error=20_results_assessment_vclust/assessment_vclust.slurm.%j.err
>
> vclust='python3.9 /home/groups/VEO/tools/vclust/v1.0.3/vclust.py'
>
> indir='10_results_assembly_flye/cross_assembly'
> outdir='20_results_assessment_vclust/cross_assembly'
> mkdir -p $outdir
> 
> $vclust prefilter -i $indir/assembly.fasta -o $outdir/fltr.txt
> $vclust align -i $indir/assembly.fasta -o $outdir/ani.tsv -t 30 --filter $outdir/fltr.txt
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_tani_90.tsv --ids $outdir/ani.ids.tsv --metric tani --tani 0.90
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_tani_70.tsv --ids $outdir/ani.ids.tsv --metric tani --tani 0.70
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_ani_90.tsv --ids $outdir/ani.ids.tsv --metric ani --ani 0.90
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusterreps.tsv --ids $outdir/ani.ids.tsv --algorithm uclust --metric ani --ani 0.95 --cov 0.85 --out-repr
> 
> source ../py3env/bin/activate
>
> python3 20_run_filter_representatives.py $indir/assembly.fasta $outdir/assembly.fasta $outdir/clusterreps.tsv
>
> deactivate
>
> indir='10_results_assembly_flye/single_assemblies'
> outdir='20_results_assessment_vclust/single_assemblies'
> mkdir -p $outdir
> 
> $vclust prefilter -i $indir/merged_single_assmblies.fasta -o $outdir/fltr.txt
> $vclust align -i $indir/merged_single_assmblies.fasta -o $outdir/ani.tsv -t 30 --filter $outdir/fltr.txt
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_tani_90.tsv --ids $outdir/ani.ids.tsv --metric tani --tani 0.90
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_tani_70.tsv --ids $outdir/ani.ids.tsv --metric tani --tani 0.70
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusters_ani_90.tsv --ids $outdir/ani.ids.tsv --metric ani --ani 0.90
> $vclust cluster -i $outdir/ani.tsv -o $outdir/clusterreps.tsv --ids $outdir/ani.ids.tsv --algorithm uclust --metric ani --ani 0.95 --cov 0.85 --out-repr
>
> source ../py3env/bin/activate
>
> python3 20_run_filter_representatives.py $indir/assembly.fasta $outdir/assembly.fasta $outdir/clusterreps.tsv
>
> deactivate
>```
> {: .source}
{: .solution}

> ## Go through the results of vClust
> vClust is a great tool to get a feeling for the diversity within your assemblies (or any kind of set of sequences).
> How many similar sequences were found in each assembly? How do the results depend on the choice of your
> metric (ANI, TANI or GANI) and your cutoff values?
{: .challenge}
