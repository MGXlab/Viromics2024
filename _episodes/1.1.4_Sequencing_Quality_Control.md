---
title: Sequencing Quality Control
teaching: 180
exercises: 0
questions: []
objectives:
- Understand the value of sequencing quality control
- Discuss how low quality reads affect genomic analysis
- Perform quality check on long-read data by creating plots
- Interpret quality check results
- Perform quality control on reads
keypoints:
- Sequencing quality control is an important first evaluation of our data
- NanoPlot can be used to evaluate read quality of long reads
- Chopper can be used to filter reads based on quality and/or length
---

Every step of a metagenomics/viromics analysis pipeline needs quality control and sanity checks.  
- What data am I working with?
- What is the quality of the data?
- Are my results what I expected them to be? Why?/Why not?

Here, we will assess the quality of DNA sequencing. 

Sequencing quality control can include:
- Removing barcodes
- Removing adapters
- Removing low-quality bases on read ends
- Filtering reads based on quality scores 

In reality, the Guppy/Dorado basecallers for nanopore sequencing already do quality control for us, so this is extra!

## Assessing Sequencing Quality

> ## Discussion
>
> Why do we need quality control?  
> 
> What is the impact of including low quality reads in downstream analyses?  
>
> What are some metrics for assessing sequencing quality?  
> 
> {: .source}
{: .challenge}

 [Nanopore sequencing quality](https://help.nanoporetech.com/en/articles/6629615-where-can-i-find-out-more-about-quality-scores)

We will use [NanoPlot](https://github.com/wdecoster/NanoPlot?tab=readme-ov-file) to assess the quality of our reads. NanoPlot is designed for long reads and uses information in the sequence files and also the metadata files to produce plots to evaluate the quality of our reads. 

> ## Exercise
>
> Run NanoPlot on your reads
> - play around with the features
> - Use fastq files and summary.txt
> - Assess the sequencing quality for each sample
> 
>```bash
> NanoPlot -t ? --plots ? --color ? --fastq barcode1.fastq.gz -o output_dir/barcode1
>```
> 
> {: .source}
{: .challenge}

### Resources
[An example sbatch script](https://github.com/vmkhot/Metagenome-workflows/blob/main/example_sbatch.md)

[How to write a for-loop to loop through your files here](https://github.com/vmkhot/useful-scripts/blob/main/Linux%20Commands%20Cheat%20Sheet.md#loops)

> ## sbatch script for NanoPlot
> ```bash
> #!/bin/bash
>#SBATCH --tasks=1
>#SBATCH --cpus-per-task=10
>#SBATCH --partition=short,standard
>#SBATCH --mem=1G
>#SBATCH --time=2:00:00
>#SBATCH --job-name=sequencing_QC
>#SBATCH --output=10_nanoplot/nanoplot.slurm.out.%j
>#SBATCH --error=10_nanoplot/nanoplot.slurm.err.%j
>
># First, we check the quality of the reads using nanoplot
># activate the conda environment containing nanoplot
>
>source /vast/groups/VEO/tools/anaconda3/etc/profile.d/conda.sh && conda activate nanoplot_v1.41.3
>
>
># Run nanoplot on 3 fastq files in a for loop
># -t : threads (cpus)
># --plots : types of plots to produce, see gallery: https://gigabaseorgigabyte.wordpress.com/2017/06/01/example-gallery-of-nanoplot/ 
># --N50 : draw the N50 vertical line on the plots
># --color : color for the plots
># -o : output directory
># to see other options for colors and prefilters, run : NanoPlot -h
>
>for fn in ../data/sequences/*.fastq.gz
>do
>
>base_f=$(basename $fn .fastq.gz)        # select just the first part of the name
>NanoPlot -t 10 --plots dot --N50 --color slateblue --fastq $fn -o 10_nanoplot/${base_f}/
>
>done
>```
> {: .source}
{: .solution}

This is an example of a plot you might get from NanoPlot. Something like this is important to look at so that you know approximately data is going to be lost when you filter by read quality or length. 

![Screenshot 2024-07-22 at 15 41 36](https://github.com/user-attachments/assets/c4a33643-5950-497b-806e-f03897703639)

> ## Exercise
>
> How does the sequencing quality of the 3 samples compare to each other?  
>  - Justify your answer using metrics from the NanoPlot results
>
> Do we need to remove any reads? Why?  
>
> How much data will be lost from each sample if we filter at a quality score of 12?
> 
> {: .source}
{: .challenge}

## Filtering Reads

Having high quality reads can significantly improve assemblies - particularly for error prone long reads. Many phages naturally have more frequent low-complexity regions in their genomes (low complexity region e.g. : AAAAAAA). Nanopore sequencing error generation is biased towards low-complexity regions - either falsely generating them or the exacerbating them - thereby creating artefacts in the viral genomes during assembly. 

We will use [Chopper](https://github.com/wdecoster/chopper) to filter our reads based on quality scores and length. This has two functions: 1) subsetting the reads to only work with HQ ones, 2) reducing assembly artefacts that we noticed during assembly

>## Filter your reads
> Build a sbatch script for chopper based on the following base-usage example and a for-loop for your reads
> Your filtering criteria:
> 1. minimum quality 14
> 2. minimum length 1000 bp
> 3. maximum length 40000 bp
>
>```bash
># base usage for filtering with minimum quality 10
>gunzip -c reads.fastq.gz | chopper -q 10| gzip > filtered_reads.fastq.gz
>
># check the help for the other options
>chopper -h
>```
>
>{: .source}
{: .challenge}


>## Chopper sbatch example
>```bash
>#!/bin/bash
>#SBATCH --tasks=1
>#SBATCH --cpus-per-task=10
>#SBATCH --partition=short,standard
>#SBATCH --mem=1G
>#SBATCH --time=2:00:00
>#SBATCH --job-name=sequencing_QC
>#SBATCH --output=20_chopper/chopper.slurm.out.%j
>#SBATCH --error=20_chopper/chopper.slurm.err.%j
>
># First, we check the quality of the reads using nanoplot
># activate the conda environment containing nanoplot
>
>source /vast/groups/VEO/tools/anaconda3/etc/profile.d/conda.sh && conda activate chopper_v0.5.0
>
># gunzip : unzip the reads
># -q : minimum read quality to keep
># -l : minimum read length to keep
># gzip: rezip the filtered reads
>
>for fn in ../data/sequences/*.fastq.gz
>do
>
>base_f=$(basename $fn .fastq.gz)        # select just the first part of the name
>gunzip -c $fn | chopper -q 14 -l 1000 --maxlength 40000 | gzip > ${base_f}_filtered_reads.fastq.gz
>
>done
>```
>{: .source}
{: .solution}


>## Exercise
>
>How many reads do you have left? (what % of the original read count?)
>What is the average quality?
>*Optional: Run Nanoplot again to show the difference in the read statistics*
>{: .source}
{: .challenge}

## GC Content
GC Content is another interesting metric to evaluate your sequences. There's no "wrong" GC content, rather it tells us about how much diversity our metagenomes/viromes might have. 

>## Exercise - making GC Plots
> - What is the GC content of your files?
>     - plot how much GC % is in each sequence
>         - Compare to a reference phage ([E. coli phage T4](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=SRR29341083&display=metadata) `./data/sequences/T4_SRR29341083.fastq`)
>      -Some libraries from python you might use are: 
>           - biopython SeqUtils and SeqIO, pandas and matplotlib: hist
>       - Interpret the distributions
>           - Are these what you expected?
>           - How would the GC content of a metagenome differ to these viromes?
>           - Describe the difference between our viromes and a phage isolate (T4)
>           - What interpretations can you make about the samples based on these plots?
>{: .source}
{: .challenge}

>## python script to make GC_content plots
>```python
>>#! usr/bin/python3
>
># import libraries
>from Bio.SeqUtils import gc_fraction
>from Bio import SeqIO
>import pandas as pd
>import numpy as np
>import gzip
>import matplotlib.pyplot as plt
>
># read in fastq.gz.gz.gz files 
>gc_62={}
>with gzip.open("../data/sequences/barcode62.fastq.gz", 'rt') as f:
>    for record in SeqIO.parse(f, "fastq"):
>        gc_62[record.id]=gc_fraction(record.seq)*100
>
>print("gc_62... done")
>
>gc_63={}
>with gzip.open("../data/sequences/barcode63.fastq.gz", 'rt') as f:
>    for record in SeqIO.parse(f, "fastq"):
>        gc_63[record.id]=gc_fraction(record.seq)*100
>print("gc_63... done")
>
>gc_64={}
>with gzip.open("../data/sequences/barcode64.fastq.gz", 'rt') as f:
>    for record in SeqIO.parse(f, "fastq"):
>        gc_64[record.id]=gc_fraction(record.seq)*100
>print("gc_64... done")
>
>gc_T4={}
>with gzip.open("../data/sequences/T4_SRR29341083.fastq.gz", 'rt') as f:
>    for record in SeqIO.parse(f, "fastq"):
>        gc_T4[record.id]=gc_fraction(record.seq)*100
>        #print(gc_fraction(record.seq)*100)
>print("gc_T4... done")
>
># convert to a pandas dataframe
># For your samples
>df_62 = pd.DataFrame([gc_62])
>df_62 = df_62.T
>df_63 = pd.DataFrame([gc_63])
>df_63 = df_63.T
>df_64 = pd.DataFrame([gc_64])
>df_64 = df_64.T
>
># For T4 phage
>df_T4 = pd.DataFrame([gc_T4])
>df_T4 = df_T4.T
>
># make a plotting function
>def make_plot(axs):
>    # We can set the number of bins with the *bins* keyword argument.
>    n_bins = 20
>
>    ax1 = axs[0]
>    ax1.hist(df_62, bins=n_bins)
>    ax1.set_title('% GC content')
>    ax1.set_ylabel('Barcode 62')
>    ax1.set_xlim(0, 100)
>    ax1.set_xticks(np.arange(0, 100, step=10))
>
>    ax2 = axs[1]
>    ax2.hist(df_63, bins=n_bins)
>    ax2.set_ylabel('Barcode 63')
>
>    ax3 = axs[2]
>    ax3.hist(df_64, bins=n_bins)
>    ax3.set_ylabel('Barcode 64')
>
>    ax4 = axs[3]
>    ax4.hist(df_T4, bins=n_bins)
>    ax4.set_ylabel('T4 Phage')
>
># Plot:
>fig, axs = plt.subplots(4,1, sharex=True, tight_layout=True)
>make_plot(axs)
>plt.show()
>
># save your plot
>fig.savefig('GC_Content.png', dpi=150)
>```
>{: .source}
{: .solution}
