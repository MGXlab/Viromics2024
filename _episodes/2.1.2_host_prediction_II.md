---
title: "Host Prediction II"
teaching: 120
exercises: 30
questions:
- ""
objectives:
- ""
keypoints:
---

# Host prediction

Today, we want to use the tool RaFAH to predict a genus of a putative host for our contigs. 
The tool predicts proteins in each viral sequence and then assigns them to a set of orthologous 
groups. The annotated proteins are then used to predict a host genus with a pretrained random 
forest model. This model matches the set of proteins with host proteins it was trained on.

> ## Exercise - Use RaFAH to predict hosts for our contigs
> RaFAH requires a single file for each contig to run. You first have to write a python
> script which separates the combined assembly into single files. You can use the package
> biopython installed in your virtual environment for this:
> 
> ~~~
> import os, sys
> from Bio import SeqIO
>
> # define file paths from the arguments
> ...
>
> # loop through the records in the combined assembly
> with open(assembly_path) as handle:
>     for record in SeqIO.parse(handle, "fasta"):
>         # set a filename per record
>         out_fasta = os.path.join(out_dir, f"{record.id}.fasta")
>         # write the record to the file
>         with open(out_fasta, "w") as fout:
>             SeqIO.write([record], fout, "fasta")
> ~~~
> {: .language-python}
>
> You can run this code in the same sbatch script as RaFAH. RaFAH is programmed in perl and
> you can find it here on draco:
> 
> ~~~
> # set some variables for running RaFAH on draco
> export PATH=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32.1:$PATH
> export PERL5LIB=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32 && 
> rafah='/home/groups/VEO/tools/rafah/RaFAH.pl'
>
> # create an output folder or use the one you set for the slurm logs:
> mkdir 10_results_hostprediction_rafah
> 
> # run RaFAH with the appropriate file paths and arguments
> perl "$rafah" --predict --genomes_dir 10_results_hostprediction_rafah/split_contigs --extension .fasta
> ~~~
> {: .language-bash}
>
> RaFAH is computationally expensive and can use multiple threads. We recommend you set the
> following sbatch parameters:
> - #SBATCH --cpus-per-task=32
> - #SBATCH --partition=standard
> - #SBATCH --mem=30G
>
> RaFAH uses the random forest model to compute a probability for all host genuses included in its training.
> You can find these probabilities in the output file `bla.csv`. The file `blabla.csv` contains per contig
> the genus with the highest probability.
{: .challenge}

> ## python script for splitting the assembly into separate files
> ```python
> import os, sys
> from Bio import SeqIO
> 
> def main():
>
>     # define file paths from the arguments
>     assembly_path = os.path.abspath(sys.argv[1])
>     assert assembly_path.endswith(".fasta")
>
>     # set an output directory and create it if it does not exist
>     out_dir = os.path.abspath(sys.argv[2])
>     if not os.path.exists(out_dir): os.makedirs(out_dir)
>
>     # loop through the records in the combined assembly
>     with open(assembly_path) as handle:
>         for record in SeqIO.parse(handle, "fasta"):
>             # set a filename per record
>             out_fasta = os.path.join(out_dir, f"{record.id}.fasta")
>             # write the record to the file
>             with open(out_fasta, "w") as fout:
>                 SeqIO.write([record], fout, "fasta")
> 
> if __name__ == "__main__":
>     main()
>```
> {: .source}
{: .solution}

> ## sbatch script for host prediction with RaFAH
> ```bash
> #!/bin/bash
> #SBATCH --tasks=1
> #SBATCH --cpus-per-task=32
> #SBATCH --partition=standard
> #SBATCH --mem=30G
> #SBATCH --time=01:00:00
> #SBATCH --job-name=hostprediction_rafah
> #SBATCH --output=10_results_hostprediction_rafah/hostprediction_rafah.slurm.%j.out
> #SBATCH --error=10_results_hostprediction_rafah/hostprediction_rafah.slurm.%j.err
> 
> # set some variables for running RaFAH on draco
> export PATH=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32.1:$PATH
> export PERL5LIB=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32 && 
> rafah='/home/groups/VEO/tools/rafah/RaFAH.pl'
> 
> # RaFAH expects each genome in a separate file. Activate our virtual environment
> # and run a python script to split our filtered assembly into single files
> source ../py3env/bin/activate
> 
> # The script requires the assmbly path and a directory for outputting the contigs
> python 10_split_assembly_file.py ../1.3_virus_identification/20_select_contigs/phage_contigs.fasta 10_results_hostprediction_rafah/split_contigs
> 
> # rafah parameters (https://gensoft.pasteur.fr/docs/RaFAH/0.3/)
> # --predict: run the pipeline for predicting hosts
> # --genomes_dir: the directory with the separate files for each contig
> # --extension: the extension of the contig files 
> perl "$rafah" --predict --genomes_dir 10_results_hostprediction_rafah/split_contigs --extension .fasta
> 
> # technically its not necessary to close the environment, 
> # the session will be terminated after the script finishes.
> deactivate
>```
> {: .source}
{: .solution}
