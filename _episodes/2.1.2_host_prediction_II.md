---
title: "Host Prediction II"
teaching: 120
exercises: 30
questions:
- ""
objectives:
- "Run RaFAH to predict a host genus for each contig."
keypoints:
- "RaFAH returns a probability for each host genus it can predict."
---

# Host prediction

Today, we want to use the tool RaFAH to predict a genus of a putative host for our contigs. 
The tool predicts proteins in each viral sequence and then assigns them to a set of orthologous 
groups. The annotated proteins are then used to predict a host genus with a pretrained random 
forest model. This model matches the set of proteins with host proteins it was trained on.

> ## Exercise - Use RaFAH to predict hosts for our contigs
> RaFAH requires a single file for each contig to run. You first have to write a python
> script which separates the combined assembly into single files. You can use the package
> biopython installed in your virtual environment for this:
> 
> ~~~
> import os, sys
> from Bio import SeqIO
>
> # define file paths from the arguments
> ...
>
> # loop through the records in the combined assembly
> with open(assembly_path) as handle:
>     for record in SeqIO.parse(handle, "fasta"):
>         # set a filename per record
>         out_fasta = os.path.join(out_dir, f"{record.id}.fasta")
>         # write the record to the file
>         with open(out_fasta, "w") as fout:
>             SeqIO.write([record], fout, "fasta")
> ~~~
> {: .language-python}
>
> You can run this code in the same sbatch script as RaFAH. Here you can find a [description of the parameters](https://gensoft.pasteur.fr/docs/RaFAH/0.3/)
> you can pass to the tool (the page is a bit hard to read). RaFAH is programmed in perl and you can find it here on draco:
> 
> ~~~
> # set some variables for running RaFAH on draco
> export PATH=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32.1:$PATH
> export PERL5LIB=/home/groups/VEO/tools/perl/build/perl-5.32.1/perl-5.32 && 
> rafah='/home/groups/VEO/tools/rafah/RaFAH.pl'
>
> # create an output folder or use the one you set for the slurm logs:
> mkdir 10_results_hostprediction_rafah
> 
> # run RaFAH with the appropriate file paths and arguments
> perl "$rafah" --predict --genomes_dir 10_results_hostprediction_rafah/split_contigs --extension .fasta
> ~~~
> {: .language-bash}
>
> RaFAH is computationally expensive and can use multiple threads. We recommend you set the
> following sbatch parameters:
> - #SBATCH --cpus-per-task=32
> - #SBATCH --partition=standard
> - #SBATCH --mem=30G
>
> RaFAH uses the random forest model to compute a probability for all host genuses included in its training.
> You can find these probabilities in the output file `*Host_Predictions.tsv`. The file `*Seq_Info_Prediction.tsv` contains per contig
> the genus with the highest probability.
>
> 1. How many contigs have a probability score larger than your chosen cutoff?
> 2. Does the probability score relate to the completeness of the contigs? (qualitative answer)
{: .challenge}

> ## python script for splitting the assembly into separate files
> ```python
> import os, sys
> from Bio import SeqIO
> 
> def main():
>
>     # define file paths from the arguments
>     assembly_path = os.path.abspath(sys.argv[1])
>     assert assembly_path.endswith(".fasta")
>
>     # set an output directory and create it if it does not exist
>     out_dir = os.path.abspath(sys.argv[2])
>     if not os.path.exists(out_dir): os.makedirs(out_dir)
>
>     # loop through the records in the combined assembly
>     with open(assembly_path) as handle:
>         for record in SeqIO.parse(handle, "fasta"):
>             # set a filename per record
>             out_fasta = os.path.join(out_dir, f"{record.id}.fasta")
>             # write the record to the file
>             with open(out_fasta, "w") as fout:
>                 SeqIO.write([record], fout, "fasta")
> 
> if __name__ == "__main__":
>     main()
>```
> {: .source}
{: .solution}

> ## python script for translating NCBI genus IDs to GTDB
> ```python
> import os, sys
> import pandas as pd
> 
> # Extract the genus part of the NCBI taxonomy.
> # This should correspond to RaFAH's output
> def get_ncbi_genus(s):
>     for ss in s.split(";"):
>         if ss.startswith("g__"): return ss[3:]
>     return "none"
> 
> # Extract the complete taxonomic classification up to genus from GTDB
> def get_gtdb_upto_genus(s):
>     return s.split(";s__")[0]
> 
> def main():
> 
>     # set the filename of the rafah output file containing the best prediction per contig
>     rafah_filename = os.path.abspath(sys.argv[1])
>     assert rafah_filename.endswith(".tsv")
> 
>     # set the filename of the translation table with NCBI and GTDB taxonomic IDs
>     translation_filename = os.path.abspath(sys.argv[2])
>     assert translation_filename.endswith(".csv")
>     
>     # set the output filename
>     out_filename = os.path.abspath(sys.argv[3])
>     assert out_filename.endswith(".csv")
> 
>     # read the input tables using pandas
>     translate_df = pd.read_csv(translation_filename)
>     rafah_df = pd.read_csv(rafah_filename, sep='\t')
> 
>     # create a dictionary for efficient matching of NCBI to GTDB
>     translation_dict = {get_ncbi_genus(r["ncbi_taxonomy"]):get_gtdb_upto_genus(r["gtdb_taxonomy"]) for i, r in translate_df.iterrows()}
> 
>     # translate all NCBI genus predictions to GTDB.
>     # We don't manipulate the table while iterating over it because this could lead to problems.
>     translated_hosts = []
>     for i, row in rafah_df.iterrows():
>         translated_hosts.append(translation_dict[row["Predicted_Host"]] if row["Predicted_Host"] in translation_dict else "no_translation") 
> 
>     # add the translated predictions to the dataframe and save the table.
>     rafah_df["Predicted_Host"] = translated_hosts
>     rafah_df.to_csv(out_filename)
> 
> if __name__ == "__main__":
>     main()
>```
> {: .source}
{: .solution}

> ## sbatch script for host prediction with RaFAH
> ```bash
> #!/bin/bash
> #SBATCH --tasks=1
> #SBATCH --cpus-per-task=32
> #SBATCH --partition=short,standard
> #SBATCH --mem=50G
> #SBATCH --time=02:00:00
> #SBATCH --job-name=rafah
> #SBATCH --output=./2.1_host_prediction/10_rafah/rafah.slurm.%j.out
> #SBATCH --error=./2.1_host_prediction/10_rafah/rafah.slurm.%j.err
> 
> assembly='./1.3_virus_identification/40_results_filter_contigs/assembly.fasta'
> contigs='./2.1_host_prediction/10_rafah/split_contigs'
>
> # RaFAH expects each genome in a separate file. Activate our virtual environment
> # and run a python script to split our filtered assembly into single files
> source ./py3env/bin/activate
> 
> # The script requires the assmbly path and a directory for outputting the contigs
> python ./python_scripts/host_prediction/10_split_assembly_file.py $assembly $contigs
>
> # deactivate the python environment, just to be sure not to cause problems with the conda environment RaFAH needs
> deactivate
>
> # activate the conda environment with the dependencies RaFAH requires
> source /vast/groups/VEO/tools/miniconda3_2024/etc/profile.d/conda.sh && conda activate perl_v5.32.1
>
> # set a variable to call the RaFAH script
> rafah='/home/groups/VEO/tools/rafah/RaFAH.pl'
> 
> # rafah parameters (https://gensoft.pasteur.fr/docs/RaFAH/0.3/)
> # --predict: run the pipeline for predicting hosts
> # --genomes_dir: the directory with the separate files for each contig
> # --extension: the extension of the contig files
> # --file_prefix: can specify an output dir here and "run name" (rafah_1) here
> 
> perl "$rafah" --predict --genomes_dir $contigs --extension .fasta --file_prefix ./2.1_host_prediction/10_rafah/rafah_1
> 
> # deactivate RaFAH's conda environment
> conda deactivate
>
> # Our python script for translating the Taxonomy needs our python environment again
> source ./py3env/bin/activate
>
> # set the path to the table with the translation between NCBI and GTDB and to RaFAH output
> translation='./2.1_host_prediction/ncbi_to_gtdb.csv'
> rafahtable='./2.1_host_prediction/10_rafah/rafah_1_Seq_Info_Prediction.tsv'
>
> # run our script with the appropriate file names as parameters
> python ./python_scripts/host_prediction/20_translate_taxonomy.py $rafahtable $translation ./2.1_host_prediction/10_rafah/rafah_1_Seq_Info_Prediction_gtdb.csv
>
> deactivate
>```
> {: .source}
{: .solution}
